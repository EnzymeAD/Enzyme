module Enzyme

export autodiff
export Const, Active, Duplicated

using LLVM
using LLVM.Interop

include("utils.jl")
include("compiler.jl")

abstract type Annotation{T} end 
struct Const{T} <: Annotation{T}
    val::T
end
struct Active{T} <: Annotation{T}
    val::T
end
struct Duplicated{T} <: Annotation{T}
    val::T
    dval::T
end

Base.eltype(::Type{<:Annotation{T}}) where T = T

struct Thunk{F, RT, TT, LLVMF}
    mod::LLVM.Module
    entry::LLVM.Function

    function Thunk(f, rt, tt; optimize=true)
        primal_tt = map(eltype, tt) 

        @show primal_tt
        @show typeof(primal_tt)

        source = Compiler.FunctionSpec(f, Tuple{primal_tt...}, #=kernel=# false)
        target = Compiler.EnzymeTarget()
        job    = Compiler.EnzymeJob(target, source)

        # Codegen the primal function and all its dependency in one module
        mod, primalf = Compiler.codegen(:llvm, job, optimize=false)

        # Now build the actual wrapper function
        ctx     = context(mod)
        rettype = convert(LLVMType, rt)

        params = parameters(primalf)
        adjoint_tt = LLVMType[]
        for (i, T) in enumerate(tt)
            llvmT = llvmtype(params[i])
            push!(adjoint_tt, llvmT)
            if T <: Duplicated 
                push!(adjoint_tt, llvmT)
            end
        end

        # create a wrapper Function that we will inline into the llvmcall
        # generated by `call_function` in `autodiff`
        llvmf = LLVM.Function(mod, "enzyme_entry", LLVM.FunctionType(rettype, adjoint_tt))
        push!(function_attributes(llvmf), EnumAttribute("alwaysinline", 0, ctx))

        # Create the FunctionType and funtion decleration for the intrinsic
        pt       = LLVM.PointerType(LLVM.Int8Type(ctx))
        ftd      = LLVM.FunctionType(rettype, LLVMType[pt], true)
        autodiff = LLVM.Function(mod, string("__enzyme_autodiff.", rt), ftd)

        params = LLVM.Value[]
        llvm_params = parameters(llvmf)
        i = 1
        for T in tt
            if T <: Const
                push!(params, MDString("diffe_const"))
            elseif T <: Active
                push!(params, MDString("diffe_out"))
            elseif T <: Duplicated
                push!(params, MDString("diffe_dup"))
                push!(params, llvm_params[i])
                i += 1
            else
                @assert("illegal annotation type")
            end
            push!(params, llvm_params[i])
            i += 1
        end

        Builder(ctx) do builder
            entry = BasicBlock(llvmf, "entry", ctx)
            position!(builder, entry)

            tc = bitcast!(builder, primalf,  pt)
            pushfirst!(params, tc)

            val = call!(builder, autodiff, params)

            ret!(builder, val)
        end

        if optimize
            # Run pipeline and Enzyme pass
            Compiler.optimize!(mod, llvmf)
        end
        strip_debuginfo!(mod)

        new{typeof(f), rt, Tuple{tt...}, llvmf}(mod, llvmf)
    end
end

# for method in (:code_typed, :code_warntype, :code_llvm, :code_native)
#     # only code_typed doesn't take a io argument
#     args = method == :code_typed ? (:job,) : (:io, :job)
#     native_method = Symbol("native_$(method)")

#     @eval begin
#         function $native_method(io::IO, @nospecialize(func), @nospecialize(types);
#                              kernel::Bool=false, minthreads=nothing, maxthreads=nothing,
#                              blocks_per_sm=nothing, maxregs=nothing, kwargs...)
#             source = FunctionSpec(func, Base.to_tuple_type(types), kernel)
#             target = NativeCompilerTarget()
#             job = NativeCompilerJob(target=target, source=source)
#             GPUCompiler.$method($(args...); kwargs...)
#         end
#         $native_method(@nospecialize(func), @nospecialize(types); kwargs...) =
#             $native_method(stdout, func, types; kwargs...)
#     end
# end

# This is rather wonky... we should instead integrate with the ORCJIT C-API
# https://github.com/JuliaGPU/GPUCompiler.jl/issues/3
# We are also re-running Julia's optimization pipeline again
@generated function (thunk::Thunk{F, RT, TT, LLVMF})(args...) where {F, RT, TT, LLVMF}
    _args = (:(args[$i]) for i in 1:length(args))
    call_function(LLVMF, Float64, Tuple{args...}, Expr(:tuple, _args...))
end

function autodiff(f, args...)
    # TODO: turn into recursive tuple function
    annotated_args = map(args) do arg
        if !(arg isa Annotation)
            return Const(arg)
        else
            return arg
        end
    end
    thunk = Thunk(f, Float64, map(Core.Typeof, annotated_args))
    thunk_args = []
    for arg in annotated_args
        push!(thunk_args, arg.val)
        if arg isa Duplicated
            push!(thunk_args, arg.dval)
        end
    end

    thunk(thunk_args...)
end
  
end # module
