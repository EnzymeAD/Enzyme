<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Users of MLIR - Enzyme AD</title><meta name=description content="Enzyme AD Compiler framework"><meta name=generator content="Hugo 0.74.3"><link href=index.xml rel=alternate type=application/rss+xml><link rel=canonical href=/users/><link rel=stylesheet href=css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=js/bundle.js></script><style>:root{}</style></head><body><div class=container><header><h1><div><img src=/mlir-logo.png width=40px align=absmiddle>
Enzyme AD</div></h1><p class=description>Enzyme AD Compiler framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://groups.google.com/d/forum/enzyme-dev>Discussion List</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/wsmoses/Enzyme>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/wsmoses/Enzyme>GitHub</a></li></ul></li><li><a href=https://github.com/wsmoses/Enzyme/issues>Bugs</a></li></ul></nav></div><div class=content-container><main><h1>Users of MLIR</h1><p>In alphabetical order below.</p><h2 id=circthttpsgithubcomllvmcirct-circuit-ir-compilers-and-tools><a href=https://github.com/llvm/circt>CIRCT</a>
: Circuit IR Compilers and Tools</h2><p>The CIRCT project is an (experimental!) effort looking to apply MLIR and the LLVM
development methodology to the domain of hardware design tools.</p><h2 id=flanghttpsgithubcomllvmllvm-projecttreemasterflang><a href=https://github.com/llvm/llvm-project/tree/master/flang>Flang</a></h2><p>Flang is a ground-up implementation of a Fortran front end written in modern C++.
It started off as the
<a href=https://github.com/flang-compiler/f18>f18 project</a>
with an
aim to replace the previous
<a href=https://github.com/flang-compiler/flang>flang project</a>
and address its various deficiencies. F18 was subsequently accepted into the LLVM
project and rechristened as Flang. The high level IR of the Fortran compiler is modeled
using MLIR.</p><h2 id=ireehttpsgithubcomgoogleiree><a href=https://github.com/google/iree>IREE</a></h2><p>IREE (pronounced &ldquo;eerie&rdquo;) is a compiler and minimal runtime system for
compiling ML models for execution against a HAL (Hardware Abstraction Layer)
that is aligned with Vulkan. It aims to be a viable way to compile and run
ML devices on a variety of small and medium sized systems, leveraging either
the GPU (via Vulkan/SPIR-V), CPU or some combination. It also aims to
interoperate seamlessly with existing users of Vulkan APIs, specifically
focused on games and rendering pipelines.</p><h2 id=npcomphttpsgithubcomllvmmlir-npcomp-mlir-based-compiler-toolkit-for-numerical-python-programs><a href=https://github.com/llvm/mlir-npcomp>NPComp</a>
: MLIR based compiler toolkit for numerical python programs</h2><p>The NPComp project aims to provide tooling for compiling numerical python programs of various forms to take advantage of MLIR+LLVM code generation and backend runtime systems.</p><p>In addition to providing a bridge to a variety of Python based numerical programming frameworks, NPComp also directly develops components for tracing and compilation of generic Python program fragments.</p><h2 id=onnx-mlirhttpsgithubcomonnxonnx-mlir><a href=https://github.com/onnx/onnx-mlir>ONNX-MLIR</a></h2><p>To represent neural network models, users often use
<a href=http://onnx.ai/onnx-mlir/>Open Neural Network
Exchange (ONNX)</a>
which is an open standard format for
machine learning interoperability.
ONNX-MLIR is a MLIR-based compiler for rewriting a model in ONNX into a standalone
binary that is executable on different target hardwares such as x86 machines,
IBM Power Systems, and IBM System Z.</p><p>See also this paper:
<a href=https://arxiv.org/abs/2008.08272>Compiling ONNX Neural Network Models Using
MLIR</a>
.</p><h2 id=plaidmlhttpsgithubcomplaidmlplaidml><a href=https://github.com/plaidml/plaidml>PlaidML</a></h2><p>PlaidML is a tensor compiler that facilitates reusable and performance portable
ML models across various hardware targets including CPUs, GPUs, and
accelerators.</p><h2 id=risehttpsrise-langorg><a href=https://rise-lang.org/>RISE</a></h2><p>RISE is a spiritual successor to the
<a href=http://www.lift-project.org/>Lift project</a>
: &ldquo;a high-level functional data
parallel language with a system of rewrite rules which encode algorithmic
and hardware-specific optimisation choices&rdquo;.</p><h2 id=trft-tensorflow-runtimehttpsgithubcomtensorflowruntime><a href=https://github.com/tensorflow/runtime>TRFT: TensorFlow Runtime</a></h2><p>TFRT aims to provide a unified, extensible infrastructure layer for an
asynchronous runtime system.</p><h2 id=tensorflowhttpswwwtensorfloworgmlir><a href=https://www.tensorflow.org/mlir>TensorFlow</a></h2><p>MLIR is used as a Graph Transformation framework and the foundation for
building many tools (XLA, TFLite converter, quantization, &mldr;).</p><h2 id=veronahttpsgithubcommicrosoftverona><a href=https://github.com/microsoft/verona>Verona</a></h2><p>Project Verona is a research programming language to explore the concept of
concurrent ownership. They are providing a new concurrency model that seamlessly
integrates ownership.</p><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=/talks/ title="Talks and Related Publications"><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - Talks and Related Publications</a>
<a class="nav nav-next" href=/getting_started/ title="Getting Started">Next - Getting Started <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href>Home</a></li><li><a href=/talks/>Talks and Related Publications</a></li><li class="parent active"><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>